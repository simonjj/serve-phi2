# Use an official Python runtime as a parent image
#FROM python:3.11-slim-bookworm
FROM nvidia/cuda:12.0.1-runtime-ubuntu22.04


# Set the working directory in the container to /app
WORKDIR /app
# make sure to adjust download_model.py to the correct path in case you make changes to HF_HOME
ENV HF_HOME=${WORKDIR}/.cache

# Add the current directory contents into the container at /app
ADD . /app

RUN apt-get update && apt-get -y install apt-utils python3 python3-pip 

RUN python3 -m pip install --no-cache-dir --upgrade pip && \
    python3 -m pip install --no-cache-dir \
    fastapi \
    torch \
    transformers \
    pydantic \
    uvicorn \
    cuda-python \
    joblib

# Install any needed packages specified in requirements.txt
RUN python3 "download_model.py"

# Make port 80 available to the world outside this container
EXPOSE 8080

# Run app.py when the container launches
CMD ["uvicorn", "serve-phi2:app", "--host", "0.0.0.0", "--port", "8080"]