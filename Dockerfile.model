# Use an official Python runtime as a parent image
#FROM python:3.11-slim-bookworm
FROM nvidia/cuda:12.0.1-runtime-ubuntu22.04


# Set the working directory in the container to /app
WORKDIR /app
ENV HF_HOME=${WORKDIR}/.cache

# Add the current directory contents into the container at /app
ADD . /app

RUN apt-get update && apt-get -y install apt-utils python3 python3-pip 

#RUN wget https://developer.download.nvidia.com/compute/cuda/12.3.2/local_installers/cuda-repo-debian12-12-3-local_12.3.2-545.23.08-1_amd64.deb && \
#    sudo dpkg -i cuda-repo-debian12-12-3-local_12.3.2-545.23.08-1_amd64.deb && \
#    sudo cp /var/cuda-repo-debian12-12-3-local/cuda-*-keyring.gpg /usr/share/keyrings/ && \
#    sudo add-apt-repository contrib && \
#    sudo apt-get update && \
#    sudo apt-get -y install cuda-toolkit-12-3 && \
#    sudo apt-get install -y cuda-drivers
RUN python3 --version


RUN python3 -m pip install --no-cache-dir --upgrade pip && \
    python3 -m pip install --no-cache-dir \
    fastapi \
    torch \
    transformers \
    pydantic \
    uvicorn \
    cuda-python \
    joblib

# Install any needed packages specified in requirements.txt
RUN python3 "download_model.py"

# Make port 80 available to the world outside this container
EXPOSE 8080

# Run app.py when the container launches
CMD ["uvicorn", "serve-phi2:app", "--host", "0.0.0.0", "--port", "8080"]